Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 1
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	all
	1	bcftools_call
	3	bwa_map
	1	plot_quals
	3	samtools_index
	3	samtools_sort
	12

[Mon Aug 19 14:45:33 2019]
rule bwa_map:
    input: data/genome.fa, data/samples/B.fastq
    output: mapped-reads/B.bam
    log: logs/bwa-mem/B.log
    jobid: 11
    wildcards: sample=B

[Mon Aug 19 14:45:34 2019]
Finished job 11.
1 of 12 steps (8%) done

[Mon Aug 19 14:45:34 2019]
rule bwa_map:
    input: data/genome.fa, data/samples/C.fastq
    output: mapped-reads/C.bam
    log: logs/bwa-mem/C.log
    jobid: 9
    wildcards: sample=C

[Mon Aug 19 14:45:36 2019]
Finished job 9.
2 of 12 steps (17%) done

[Mon Aug 19 14:45:36 2019]
rule bwa_map:
    input: data/genome.fa, data/samples/A.fastq
    output: mapped-reads/A.bam
    log: logs/bwa-mem/A.log
    jobid: 10
    wildcards: sample=A

[Mon Aug 19 14:45:37 2019]
Finished job 10.
3 of 12 steps (25%) done

[Mon Aug 19 14:45:37 2019]
rule samtools_sort:
    input: mapped-reads/C.bam
    output: sorted-reads/C.bam
    jobid: 3
    wildcards: sample=C

[Mon Aug 19 14:45:37 2019]
Finished job 3.
4 of 12 steps (33%) done

[Mon Aug 19 14:45:37 2019]
rule samtools_sort:
    input: mapped-reads/B.bam
    output: sorted-reads/B.bam
    jobid: 7
    wildcards: sample=B

[Mon Aug 19 14:45:37 2019]
Finished job 7.
5 of 12 steps (42%) done

[Mon Aug 19 14:45:37 2019]
rule samtools_sort:
    input: mapped-reads/A.bam
    output: sorted-reads/A.bam
    jobid: 4
    wildcards: sample=A

[Mon Aug 19 14:45:38 2019]
Finished job 4.
6 of 12 steps (50%) done

[Mon Aug 19 14:45:38 2019]
rule samtools_index:
    input: sorted-reads/C.bam
    output: sorted-reads/C.bam.bai
    jobid: 6
    wildcards: sample=C

[Mon Aug 19 14:45:38 2019]
Finished job 6.
7 of 12 steps (58%) done

[Mon Aug 19 14:45:38 2019]
rule samtools_index:
    input: sorted-reads/B.bam
    output: sorted-reads/B.bam.bai
    jobid: 8
    wildcards: sample=B

[Mon Aug 19 14:45:38 2019]
Finished job 8.
8 of 12 steps (67%) done

[Mon Aug 19 14:45:38 2019]
rule samtools_index:
    input: sorted-reads/A.bam
    output: sorted-reads/A.bam.bai
    jobid: 5
    wildcards: sample=A

[Mon Aug 19 14:45:38 2019]
Finished job 5.
9 of 12 steps (75%) done

[Mon Aug 19 14:45:38 2019]
rule bcftools_call:
    input: data/genome.fa, sorted-reads/A.bam, sorted-reads/B.bam, sorted-reads/C.bam, sorted-reads/A.bam.bai, sorted-reads/B.bam.bai, sorted-reads/C.bam.bai
    output: calls/all.vcf
    jobid: 2

[Mon Aug 19 14:45:38 2019]
Finished job 2.
10 of 12 steps (83%) done

[Mon Aug 19 14:45:38 2019]
rule plot_quals:
    input: calls/all.vcf
    output: plots/quals.svg
    jobid: 1

[Mon Aug 19 14:45:38 2019]
Error in rule plot_quals:
    jobid: 1
    output: plots/quals.svg

RuleException:
WorkflowError in line 87 of /Users/Jessica/Documents/codehub/snakemake/snakemake-tutorial/Snakefile:
URLError: <urlopen error [Errno 2] No such file or directory: '/Users/Jessica/Documents/codehub/snakemake/snakemake-tutorial/scripts/plot-quals.py'>
  File "/Users/Jessica/Documents/codehub/snakemake/snakemake-tutorial/Snakefile", line 87, in __rule_plot_quals
  File "/Users/Jessica/miniconda3/envs/snakemake-tutorial/lib/python3.6/concurrent/futures/thread.py", line 56, in run
Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: /Users/Jessica/Documents/codehub/snakemake/snakemake-tutorial/.snakemake/log/2019-08-19T144533.582718.snakemake.log
